"""
å­¦æœ¯æ–‡çŒ®æ™ºèƒ½å¯¼è¯»ä¸å¯è§†åŒ–åˆ†æç³»ç»Ÿ
Academic Literature Intelligent Guidance System

ä¸»åº”ç”¨å…¥å£
"""

import streamlit as st
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from config import get_api_key
from core.document_processor import DocumentProcessor
from core.vector_store import VectorStoreManager
from core.rag_chain import RAGChain
from core.entity_extractor import EntityExtractor
from core.knowledge_graph import KnowledgeGraph
from ui import (
    init_page_config,
    get_custom_css,
    render_chat_message,
    render_source_documents,
    render_sidebar_api_config,
    render_sidebar_info,
    render_quick_questions,
    render_chat_qa_item
)
from ui.graph_view import (
    render_graph_in_streamlit,
    render_graph_statistics,
    render_legend
    # [REMOVED] render_entity_source_buttons - å¦‚éœ€æ¢å¤ï¼Œå–æ¶ˆæ³¨é‡Šå¹¶å–æ¶ˆä¸‹æ–¹è°ƒç”¨å¤„çš„æ³¨é‡Š
)


def init_session_state():
    """åˆå§‹åŒ– session state"""
    if "vector_store_manager" not in st.session_state:
        st.session_state.vector_store_manager = None
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "documents_loaded" not in st.session_state:
        st.session_state.documents_loaded = False
    if "uploaded_files_info" not in st.session_state:
        st.session_state.uploaded_files_info = []
    if "api_key" not in st.session_state:
        st.session_state.api_key = get_api_key()
    if "pending_quick_question" not in st.session_state:
        st.session_state.pending_quick_question = None
    # çŸ¥è¯†å›¾è°±ç›¸å…³çŠ¶æ€
    if "knowledge_graph" not in st.session_state:
        st.session_state.knowledge_graph = KnowledgeGraph()
    if "entities_extracted" not in st.session_state:
        st.session_state.entities_extracted = False
    if "processed_chunks" not in st.session_state:
        st.session_state.processed_chunks = []


def process_uploaded_files(uploaded_files, api_key: str):
    """
    å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
    
    Args:
        uploaded_files: Streamlit ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨
        api_key: API Key
    """
    if not uploaded_files:
        return
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    doc_processor = DocumentProcessor()
    
    # åˆå§‹åŒ–æˆ–è·å–å‘é‡å­˜å‚¨ç®¡ç†å™¨
    if st.session_state.vector_store_manager is None:
        st.session_state.vector_store_manager = VectorStoreManager(api_key=api_key)
    
    all_chunks = []
    files_info = []
    
    for uploaded_file in uploaded_files:
        filename = uploaded_file.name
        
        with st.spinner(f"ğŸ“– æ­£åœ¨å¤„ç† {filename}..."):
            try:
                # å¤„ç†æ–‡ä»¶ï¼šè§£æ + åˆ‡åˆ†
                chunks = doc_processor.process_uploaded_file(
                    uploaded_file,
                    filename,
                    clean=True  # æ¸…æ´—æ–‡æœ¬ï¼Œç§»é™¤å‚è€ƒæ–‡çŒ®ç­‰
                )
                
                all_chunks.extend(chunks)
                files_info.append({
                    "name": filename,
                    "size": uploaded_file.size,
                    "chunks": len(chunks)
                })
                
                st.success(f"âœ… {filename}: è§£æå®Œæˆï¼Œç”Ÿæˆ {len(chunks)} ä¸ªæ–‡æœ¬å—")
                
            except Exception as e:
                st.error(f"âŒ å¤„ç† {filename} æ—¶å‡ºé”™: {str(e)}")
    
    if all_chunks:
        with st.spinner("ğŸ”¢ æ­£åœ¨åˆ›å»ºå‘é‡ç´¢å¼•..."):
            try:
                # åˆ›å»ºå‘é‡å­˜å‚¨
                st.session_state.vector_store_manager.create_from_documents(
                    all_chunks,
                    persist=True
                )
                
                st.session_state.documents_loaded = True
                st.session_state.uploaded_files_info = files_info
                # ä¿å­˜ chunks ä¾›çŸ¥è¯†å›¾è°±ä½¿ç”¨
                st.session_state.processed_chunks = all_chunks
                # é‡ç½®çŸ¥è¯†å›¾è°±çŠ¶æ€ï¼ˆéœ€è¦é‡æ–°æå–å®ä½“ï¼‰
                st.session_state.knowledge_graph = KnowledgeGraph()
                st.session_state.entities_extracted = False
                
                total_chunks = sum(f["chunks"] for f in files_info)
                st.success(f"âœ… å‘é‡ç´¢å¼•åˆ›å»ºæˆåŠŸï¼å…±å¤„ç† {len(files_info)} ä¸ªæ–‡ä»¶ï¼Œ{total_chunks} ä¸ªæ–‡æœ¬å—")
                
            except Exception as e:
                st.error(f"âŒ åˆ›å»ºå‘é‡ç´¢å¼•æ—¶å‡ºé”™: {str(e)}")


def handle_question(question: str, api_key: str, selected_docs: list = None):
    """
    å¤„ç†ç”¨æˆ·é—®é¢˜
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
        api_key: API Key
        selected_docs: é€‰ä¸­çš„æ–‡æ¡£åç§°åˆ—è¡¨ï¼ˆç”¨äºè¿‡æ»¤æ£€ç´¢èŒƒå›´ï¼‰
    """
    if not question.strip():
        return
    
    if not st.session_state.documents_loaded:
        st.warning("è¯·å…ˆä¸Šä¼ å¹¶å¤„ç†æ–‡æ¡£")
        return
    
    with st.spinner("ğŸ¤” æ­£åœ¨æ€è€ƒ..."):
        try:
            # è·å–æ£€ç´¢å™¨ï¼ˆæ ¹æ®æ˜¯å¦æœ‰æ–‡æ¡£é€‰æ‹©å†³å®šæ˜¯å¦è¿‡æ»¤ï¼‰
            all_doc_names = [d.get("name") for d in st.session_state.uploaded_files_info]
            
            # åˆ¤æ–­æ˜¯å¦éœ€è¦è¿‡æ»¤ï¼šåªæœ‰å½“é€‰æ‹©äº†éƒ¨åˆ†æ–‡æ¡£æ—¶æ‰è¿‡æ»¤
            if selected_docs and set(selected_docs) != set(all_doc_names):
                # ç”¨æˆ·é€‰æ‹©äº†éƒ¨åˆ†æ–‡æ¡£ï¼Œä½¿ç”¨è¿‡æ»¤æ£€ç´¢å™¨
                retriever = st.session_state.vector_store_manager.as_retriever_filtered(selected_docs)
            else:
                # å…¨é€‰æˆ–æœªæŒ‡å®šï¼Œä½¿ç”¨æ™®é€šæ£€ç´¢å™¨
                retriever = st.session_state.vector_store_manager.as_retriever()
            
            # åˆ›å»º RAG é“¾
            rag_chain = RAGChain(retriever, api_key=api_key)
            
            # æ‰§è¡ŒæŸ¥è¯¢
            result = rag_chain.query(question)
            
            # ä¿å­˜åˆ°å†å²è®°å½•ï¼ˆåŒ…å«é€‰ä¸­çš„æ–‡æ¡£ä¿¡æ¯ï¼‰
            st.session_state.chat_history.append({
                "question": question,
                "answer": result["answer"],
                "sources": result["sources"],
                "selected_docs": selected_docs or []  # ä¿å­˜æé—®æ—¶é€‰æ‹©çš„æ–‡æ¡£
            })
            
            
            # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºæ–°æ¶ˆæ¯
            st.rerun()
            
        except Exception as e:
            st.error(f"âŒ å›ç­”é—®é¢˜æ—¶å‡ºé”™: {str(e)}")


def render_document_status():
    """æ¸²æŸ“æ–‡æ¡£çŠ¶æ€ä¿¡æ¯"""
    if st.session_state.documents_loaded:
        st.success("âœ… æ–‡æ¡£å·²åŠ è½½ï¼Œå¯ä»¥å¼€å§‹æé—®ï¼")
        
        # æ˜¾ç¤ºå·²ä¸Šä¼ çš„æ–‡ä»¶ä¿¡æ¯
        if st.session_state.uploaded_files_info:
            with st.expander("ğŸ“‹ å·²åŠ è½½çš„æ–‡æ¡£", expanded=False):
                for f in st.session_state.uploaded_files_info:
                    st.markdown(f"- **{f['name']}** ({f['size']/1024:.1f} KB, {f['chunks']} ä¸ªæ–‡æœ¬å—)")
        
        # æ¸…é™¤æŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰æ–‡æ¡£", use_container_width=True):
            if st.session_state.vector_store_manager:
                st.session_state.vector_store_manager.clear()
            st.session_state.vector_store_manager = None
            st.session_state.documents_loaded = False
            st.session_state.uploaded_files_info = []
            st.session_state.chat_history = []
            # æ¸…é™¤çŸ¥è¯†å›¾è°±ç›¸å…³çŠ¶æ€
            st.session_state.knowledge_graph = KnowledgeGraph()
            st.session_state.entities_extracted = False
            st.session_state.processed_chunks = []
            st.rerun()
    else:
        st.info("â³ è¯·ä¸Šä¼ æ–‡æ¡£å¼€å§‹ä½¿ç”¨")


def render_chat_interface(api_key: str):
    """
    æ¸²æŸ“èŠå¤©ç•Œé¢ï¼ˆä½¿ç”¨åŸç”Ÿ st.chat_message å’Œ st.chat_inputï¼‰
    
    Args:
        api_key: API Key
    """
    st.subheader("ğŸ’¬ æ™ºèƒ½é—®ç­”")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„å¿«æ·é—®é¢˜
    if "pending_quick_question" in st.session_state and st.session_state.pending_quick_question:
        pending_q = st.session_state.pending_quick_question
        selected = st.session_state.get("selected_docs_for_qa", None)
        st.session_state.pending_quick_question = None  # æ¸…é™¤å¾…å¤„ç†é—®é¢˜
        handle_question(pending_q, api_key, selected)
    
    # æ¸²æŸ“å†å²æ¶ˆæ¯ï¼ˆä½¿ç”¨åŸç”Ÿ chat_message ç»„ä»¶ï¼‰
    for i, chat in enumerate(st.session_state.chat_history):
        render_chat_qa_item(chat, index=i, is_latest=(i == len(st.session_state.chat_history) - 1))
    
    # é—®ç­”è¾“å…¥åŒº
    if st.session_state.documents_loaded and api_key:
        # å¿«æ·é—®é¢˜åŒºåŸŸï¼ˆæ”¾åœ¨èŠå¤©æ¶ˆæ¯å’Œè¾“å…¥æ¡†ä¹‹é—´ï¼‰
        with st.container():
            quick_q, selected_docs = render_quick_questions(st.session_state.uploaded_files_info)
            
            # ä¿å­˜å½“å‰é€‰ä¸­çš„æ–‡æ¡£ï¼ˆç”¨äºæ£€ç´¢è¿‡æ»¤ï¼‰
            st.session_state.selected_docs_for_qa = selected_docs
            
            # å¦‚æœç‚¹å‡»äº†å¿«æ·é—®é¢˜ï¼Œä¿å­˜åˆ° pending çŠ¶æ€å¹¶åˆ·æ–°
            if quick_q:
                st.session_state.pending_quick_question = quick_q
                st.rerun()
        
        st.markdown("---")
        
        # æ¸…é™¤å¯¹è¯æŒ‰é’®ï¼ˆæ”¾åœ¨è¾“å…¥æ¡†ä¸Šæ–¹ï¼‰
        col1, col2 = st.columns([5, 1])
        with col2:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯", use_container_width=True):
                st.session_state.chat_history = []
                st.rerun()
        
        # ä½¿ç”¨åŸç”Ÿ st.chat_input æ›¿ä»£ text_input + button
        # chat_input è‡ªåŠ¨å›ºå®šåœ¨é¡µé¢åº•éƒ¨ï¼Œæ”¯æŒ Enter æäº¤
        if question := st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜...", key="chat_input"):
            # è·å–å½“å‰é€‰ä¸­çš„æ–‡æ¡£
            selected = st.session_state.get("selected_docs_for_qa", None)
            handle_question(question, api_key, selected)
                
    elif not st.session_state.documents_loaded:
        st.info("ğŸ‘† è¯·å…ˆä¸Šä¼ å¹¶å¤„ç†æ–‡æ¡£")
    elif not api_key:
        st.warning("ğŸ‘ˆ è¯·åœ¨ä¾§è¾¹æ é…ç½® API Key")


def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–é¡µé¢é…ç½®
    init_page_config()
    
    # åˆå§‹åŒ– session state
    init_session_state()
    
    # æ¸²æŸ“ä¾§è¾¹æ 
    api_key = render_sidebar_api_config()
    st.session_state.api_key = api_key
    render_sidebar_info()
    
    # ä¸»æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸ“š å­¦æœ¯æ–‡çŒ®æ™ºèƒ½å¯¼è¯»ç³»ç»Ÿ</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">åŸºäºçŸ¥è¯†å›¾è°±å¢å¼ºçš„ RAG æ–‡æ¡£é—®ç­”ä¸å¯è§†åŒ–åˆ†æ</p>', unsafe_allow_html=True)
    
    # ä½¿ç”¨ Tab ç»„ç»‡ç•Œé¢
    tab1, tab2, tab3 = st.tabs(["ğŸ“¤ æ–‡æ¡£ä¸Šä¼ ", "ğŸ’¬ æ™ºèƒ½é—®ç­”", "ğŸŒ çŸ¥è¯†å›¾è°±"])
    
    with tab1:
        st.subheader("ğŸ“¤ ä¸Šä¼ æ–‡æ¡£")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # æ–‡ä»¶ä¸Šä¼ 
            uploaded_files = st.file_uploader(
                "é€‰æ‹© PDF æˆ– Word æ–‡ä»¶",
                type=["pdf", "docx", "doc"],
                accept_multiple_files=True,
                help="æ”¯æŒåŒæ—¶ä¸Šä¼ å¤šä¸ªæ–‡ä»¶"
            )
            
            if uploaded_files:
                st.write(f"ğŸ“„ å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
                for f in uploaded_files:
                    st.write(f"  - {f.name} ({f.size/1024:.1f} KB)")
                
                if st.button("ğŸš€ å¤„ç†æ–‡æ¡£", use_container_width=True):
                    if not api_key:
                        st.error("è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
                    else:
                        process_uploaded_files(uploaded_files, api_key)
        
        with col2:
            st.subheader("ğŸ“Š çŠ¶æ€")
            render_document_status()
    
    with tab2:
        render_chat_interface(api_key)
    
    with tab3:
        st.subheader("ğŸ—ºï¸ è®ºæ–‡åœ°å›¾ - çŸ¥è¯†å›¾è°±")
        
        if not st.session_state.documents_loaded:
            st.info("ğŸ‘† è¯·å…ˆåœ¨ã€Œæ–‡æ¡£ä¸Šä¼ ã€é¡µé¢ä¸Šä¼ å¹¶å¤„ç†æ–‡æ¡£")
        else:
            # å®ä½“æå–æŒ‰é’®
            col1, col2 = st.columns([1, 3])
            with col1:
                extract_btn = st.button(
                    "ğŸ” æå–å®ä½“" if not st.session_state.entities_extracted else "ğŸ”„ é‡æ–°æå–",
                    use_container_width=True
                )
            with col2:
                if st.session_state.entities_extracted:
                    st.success("âœ… å®ä½“å·²æå–ï¼Œå›¾è°±å·²ç”Ÿæˆ")
                else:
                    st.info("ç‚¹å‡»ã€Œæå–å®ä½“ã€æŒ‰é’®å¼€å§‹æ„å»ºçŸ¥è¯†å›¾è°±")
            
            # æ‰§è¡Œå®ä½“æå–
            if extract_btn and api_key:
                # ä½¿ç”¨ st.status æ˜¾ç¤ºå®æ—¶è¿›åº¦
                with st.status("ğŸ” æ­£åœ¨ä½¿ç”¨ AI æå–æ–‡æ¡£å®ä½“...", expanded=True) as status:
                    progress_container = st.empty()
                    progress_messages = []
                    
                    def progress_callback(message: str, level: str):
                        """æ¥æ”¶è¿›åº¦æ›´æ–°å¹¶æ˜¾ç¤ºåœ¨ UI ä¸Š"""
                        # æ ¹æ® level è®¾ç½®æ ·å¼
                        if level == "file":
                            styled_msg = f"**{message}**"
                        elif level == "success":
                            styled_msg = f"âœ… {message}"
                        elif level == "error":
                            styled_msg = f"âš ï¸ {message}"
                        else:
                            styled_msg = message
                        
                        progress_messages.append(styled_msg)
                        # åªæ˜¾ç¤ºæœ€è¿‘ 10 æ¡æ¶ˆæ¯ï¼Œé¿å…è¿‡é•¿
                        recent_messages = progress_messages[-10:]
                        progress_container.markdown("\n\n".join(recent_messages))
                    
                    try:
                        # åˆ›å»ºå®ä½“æå–å™¨
                        extractor = EntityExtractor(api_key=api_key)
                        
                        # ä» chunks ä¸­æå–å®ä½“ï¼Œä¼ å…¥è¿›åº¦å›è°ƒ
                        extraction_results = extractor.extract_from_documents(
                            st.session_state.processed_chunks,
                            progress_callback=progress_callback
                        )
                        
                        # æ›´æ–°çŠ¶æ€ä¸ºæ„å»ºå›¾è°±
                        status.update(label="ğŸ“Š æ­£åœ¨æ„å»ºçŸ¥è¯†å›¾è°±...", state="running")
                        progress_callback("ğŸ“Š æ­£åœ¨æ„å»ºçŸ¥è¯†å›¾è°±...", "info")
                        
                        # æ„å»ºçŸ¥è¯†å›¾è°±
                        st.session_state.knowledge_graph = KnowledgeGraph()
                        st.session_state.knowledge_graph.build_from_extraction_results(
                            extraction_results
                        )
                        
                        # ä¿å­˜å›¾è°±
                        st.session_state.knowledge_graph.save()
                        st.session_state.entities_extracted = True
                        
                        # å®ŒæˆçŠ¶æ€
                        total_entities = sum(
                            sum(len(v) for v in entities.values())
                            for entities in extraction_results.values()
                        )
                        status.update(
                            label=f"âœ… å®Œæˆï¼æˆåŠŸä» {len(extraction_results)} ä¸ªæ–‡æ¡£æå– {total_entities} ä¸ªå®ä½“",
                            state="complete",
                            expanded=False
                        )
                        st.rerun()
                        
                    except Exception as e:
                        status.update(label="âŒ å®ä½“æå–å¤±è´¥", state="error")
                        st.error(f"âŒ å®ä½“æå–å¤±è´¥: {str(e)}")
            
            # æ˜¾ç¤ºçŸ¥è¯†å›¾è°±
            if st.session_state.entities_extracted:
                st.markdown("---")
                
                # å›¾ä¾‹
                render_legend()
                
                # å›¾è°±ç»Ÿè®¡
                stats = st.session_state.knowledge_graph.get_statistics()
                render_graph_statistics(stats)
                
                # [REMOVED] å®ä½“æ¥æºè¿½æº¯åŠŸèƒ½ - å¦‚éœ€æ¢å¤ï¼Œå–æ¶ˆä»¥ä¸‹æ³¨é‡Šï¼š
                # render_entity_source_buttons(stats, st.session_state.knowledge_graph)
                
                # st.markdown("---")
                st.markdown("### ğŸ“Š äº¤äº’å¼è®ºæ–‡åœ°å›¾")
                st.caption("æç¤ºï¼šå¯æ‹–æ‹½èŠ‚ç‚¹ï¼Œæ‚¬åœæŸ¥çœ‹è¯¦æƒ…ï¼Œç‚¹å‡»èŠ‚ç‚¹æŸ¥çœ‹è¿æ¥å…³ç³»")
                
                # æ¸²æŸ“å›¾è°± (ä½¿ç”¨é»˜è®¤é«˜åº¦750)
                render_graph_in_streamlit(
                    st.session_state.knowledge_graph.graph,
                    key="main_knowledge_graph",
                    doc_entity_map=stats.get("document_entities", {})
                )
    
    # åº•éƒ¨ä¿¡æ¯
    st.markdown("---")
    st.markdown(
        '<p class="footer">ğŸ’¡ åŸºäº LangChain + ChromaDB + Streamlit æ„å»ºçš„å­¦æœ¯æ–‡çŒ®æ™ºèƒ½åˆ†æç³»ç»Ÿ</p>',
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()
