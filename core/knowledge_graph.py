"""
çŸ¥è¯†å›¾è°±æ„å»ºæ¨¡å—
ä½¿ç”¨ NetworkX æ„å»ºæ–‡æ¡£-å®ä½“å…±ç°ç½‘ç»œ

ä¸»è¦åŠŸèƒ½ï¼š
- æ„å»ºæ–‡æ¡£ä¸å®ä½“çš„å…³è”å›¾
- æ”¯æŒå¤šç§å®ä½“ç±»å‹ï¼ˆå…³é”®è¯ã€æ–¹æ³•ã€æ•°æ®é›†ï¼‰
- å›¾è°±æŒä¹…åŒ–ä¸åŠ è½½
"""

import json
import os
from typing import Dict, List, Optional, Set, Tuple, Any
from pathlib import Path
import networkx as nx

import sys
sys.path.append(str(Path(__file__).parent.parent))
from config import GRAPHS_DIR


# èŠ‚ç‚¹ç±»å‹å¸¸é‡
NODE_TYPE_DOCUMENT = "document"
NODE_TYPE_KEYWORD = "keyword"
NODE_TYPE_METHOD = "method"
NODE_TYPE_DATASET = "dataset"
NODE_TYPE_FIELD = "field"  # ç ”ç©¶é¢†åŸŸ
NODE_TYPE_APPLICATION = "application"  # åº”ç”¨åœºæ™¯

# è¾¹ç±»å‹å¸¸é‡
EDGE_CONTAINS_KEYWORD = "CONTAINS_KEYWORD"
EDGE_USES_METHOD = "USES_METHOD"
EDGE_USES_DATASET = "USES_DATASET"
EDGE_BELONGS_TO_FIELD = "BELONGS_TO_FIELD"
EDGE_HAS_APPLICATION = "HAS_APPLICATION"


class KnowledgeGraph:
    """
    çŸ¥è¯†å›¾è°±ç±»
    å°è£… NetworkX å›¾æ“ä½œï¼Œæ„å»ºæ–‡æ¡£-å®ä½“å…±ç°ç½‘ç»œ
    """
    
    def __init__(self):
        """åˆå§‹åŒ–çŸ¥è¯†å›¾è°±"""
        # ä½¿ç”¨æ— å‘å›¾
        self.graph = nx.Graph()
        
        # å­˜å‚¨æ–‡æ¡£åŠå…¶å®ä½“çš„æ˜ å°„
        self._document_entities: Dict[str, Dict[str, List[str]]] = {}
        
        # å®ä½“ç»Ÿè®¡ - æ”¯æŒæ›´å¤šå®ä½“ç±»å‹
        self._entity_counts: Dict[str, Dict[str, int]] = {
            "keywords": {},
            "methods": {},
            "datasets": {},
            "fields": {},
            "applications": {}
        }
        
        # å®ä½“è§„èŒƒåŒ–æ˜ å°„ï¼šåŸºç¡€åç§°(å°å†™) -> è§„èŒƒå½¢å¼
        # ç”¨äºåˆå¹¶ç›¸åŒåŸºç¡€åç§°ä½†ä¸åŒæ³¨é‡Šçš„å®ä½“
        self._entity_canonical_forms: Dict[str, str] = {}
    
    def _extract_base_name(self, entity_name: str) -> str:
        """
        æå–å®ä½“çš„åŸºç¡€åç§°ï¼ˆæ‹¬å·å‰çš„éƒ¨åˆ†ï¼‰
        
        ä¾‹å¦‚:
        - "OLAF (OLAFæ–¹æ³•)" -> "olaf"
        - "OLAF (åœ¨çº¿å­¦ä¹ ä¸åé¦ˆ)" -> "olaf"
        - "Large Language Model (å¤§è¯­è¨€æ¨¡å‹)" -> "large language model"
        """
        import re
        # åŒ¹é…ç¬¬ä¸€ä¸ªæ‹¬å·å‰çš„å†…å®¹
        match = re.match(r'^([^(\[ï¼ˆã€]+)', entity_name)
        if match:
            return match.group(1).strip().lower()
        return entity_name.strip().lower()
    
    def _normalize_entity(self, entity_name: str) -> str:
        """
        å®ä½“å½’ä¸€åŒ–å¤„ç†ï¼šåˆå¹¶ç›¸åŒåŸºç¡€åç§°çš„å®ä½“
        
        è§„åˆ™ï¼š
        1. æå–åŸºç¡€åç§°ï¼ˆæ‹¬å·å‰çš„éƒ¨åˆ†ï¼‰
        2. å¦‚æœå·²å­˜åœ¨ç›¸åŒåŸºç¡€åç§°ï¼Œæ¯”è¾ƒå¹¶ä¿ç•™æ³¨é‡Šæ›´å®Œæ•´çš„ç‰ˆæœ¬
        3. ä¼˜å…ˆä¿ç•™åŒ…å«ä¸­æ–‡æ³¨é‡Šä¸”æœ€é•¿çš„ç‰ˆæœ¬
        
        Args:
            entity_name: åŸå§‹å®ä½“åç§°
            
        Returns:
            å½’ä¸€åŒ–åçš„å®ä½“åç§°
        """
        if not entity_name:
            return entity_name
        
        # å»é™¤é¦–å°¾ç©ºæ ¼
        entity_name = entity_name.strip()
        
        # æå–åŸºç¡€åç§°ä½œä¸ºé”®
        base_name = self._extract_base_name(entity_name)
        
        if base_name in self._entity_canonical_forms:
            # å·²å­˜åœ¨ç›¸åŒåŸºç¡€åç§°çš„å®ä½“
            existing = self._entity_canonical_forms[base_name]
            
            # æ¯”è¾ƒå¹¶ä¿ç•™æ›´å®Œæ•´çš„ç‰ˆæœ¬
            # ä¼˜å…ˆçº§: 1) åŒ…å«ä¸­æ–‡ 2) æ›´é•¿ 3) åŒ…å«æ‹¬å·æ³¨é‡Š
            def score(name):
                """è®¡ç®—å®ä½“åç§°çš„å®Œæ•´æ€§åˆ†æ•°"""
                score = 0
                # åŒ…å«ä¸­æ–‡åŠ åˆ†
                if any('\u4e00' <= c <= '\u9fff' for c in name):
                    score += 100
                # åŒ…å«æ‹¬å·æ³¨é‡ŠåŠ åˆ†
                if '(' in name or 'ï¼ˆ' in name:
                    score += 50
                # é•¿åº¦åŠ åˆ†ï¼ˆä½†ä¸èƒ½å¤ªé•¿ï¼‰
                score += min(len(name), 80)
                return score
            
            if score(entity_name) > score(existing):
                # æ–°ç‰ˆæœ¬æ›´å®Œæ•´ï¼Œæ›´æ–°è§„èŒƒå½¢å¼
                self._entity_canonical_forms[base_name] = entity_name
                return entity_name
            else:
                # ä½¿ç”¨å·²æœ‰çš„è§„èŒƒå½¢å¼
                return existing
        else:
            # æ–°å®ä½“ï¼Œå°†å½“å‰å½¢å¼ä½œä¸ºè§„èŒƒå½¢å¼
            self._entity_canonical_forms[base_name] = entity_name
            return entity_name
    
    def add_document(
        self,
        doc_name: str,
        entities: Dict[str, List[str]]
    ) -> None:
        """
        æ·»åŠ æ–‡æ¡£åŠå…¶å®ä½“åˆ°å›¾è°±
        
        Args:
            doc_name: æ–‡æ¡£åç§°
            entities: å®ä½“å­—å…¸ï¼ŒåŒ…å« keywords, methods, datasets
        """
        # æ¸…ç†æ–‡æ¡£åï¼ˆç§»é™¤è·¯å¾„ï¼Œåªä¿ç•™æ–‡ä»¶åï¼‰
        doc_name = Path(doc_name).stem if "/" in doc_name or "\\" in doc_name else doc_name
        
        # å½’ä¸€åŒ–æ‰€æœ‰å®ä½“ï¼ˆåˆå¹¶å¤§å°å†™å·®å¼‚ï¼‰
        normalized_entities = {}
        for entity_type, entity_list in entities.items():
            normalized_list = [self._normalize_entity(e) for e in entity_list if e]
            # å»é‡ï¼ˆåŒä¸€æ–‡æ¡£å†…ï¼‰
            normalized_entities[entity_type] = list(dict.fromkeys(normalized_list))
        
        # å­˜å‚¨æ–‡æ¡£å®ä½“æ˜ å°„ï¼ˆä½¿ç”¨å½’ä¸€åŒ–åçš„å®ä½“ï¼‰
        self._document_entities[doc_name] = normalized_entities
        
        # æ·»åŠ æ–‡æ¡£èŠ‚ç‚¹
        self.graph.add_node(
            doc_name,
            node_type=NODE_TYPE_DOCUMENT,
            label=doc_name,
            title=f"ğŸ“„ {doc_name}"
        )
        
        # æ·»åŠ å…³é”®è¯èŠ‚ç‚¹å’Œè¾¹
        for keyword in normalized_entities.get("keywords", []):
            self._add_entity_node(keyword, NODE_TYPE_KEYWORD)
            self.graph.add_edge(
                doc_name, keyword,
                edge_type=EDGE_CONTAINS_KEYWORD,
                weight=1.0
            )
            self._entity_counts["keywords"][keyword] = \
                self._entity_counts["keywords"].get(keyword, 0) + 1
        
        # æ·»åŠ æ–¹æ³•èŠ‚ç‚¹å’Œè¾¹
        for method in normalized_entities.get("methods", []):
            self._add_entity_node(method, NODE_TYPE_METHOD)
            self.graph.add_edge(
                doc_name, method,
                edge_type=EDGE_USES_METHOD,
                weight=1.5  # æ–¹æ³•å…³è”æƒé‡æ›´é«˜
            )
            self._entity_counts["methods"][method] = \
                self._entity_counts["methods"].get(method, 0) + 1
        
        # æ·»åŠ æ•°æ®é›†èŠ‚ç‚¹å’Œè¾¹
        for dataset in normalized_entities.get("datasets", []):
            self._add_entity_node(dataset, NODE_TYPE_DATASET)
            self.graph.add_edge(
                doc_name, dataset,
                edge_type=EDGE_USES_DATASET,
                weight=1.2
            )
            self._entity_counts["datasets"][dataset] = \
                self._entity_counts["datasets"].get(dataset, 0) + 1
        
        # æ·»åŠ ç ”ç©¶é¢†åŸŸèŠ‚ç‚¹å’Œè¾¹
        for field in normalized_entities.get("fields", []):
            self._add_entity_node(field, NODE_TYPE_FIELD)
            self.graph.add_edge(
                doc_name, field,
                edge_type=EDGE_BELONGS_TO_FIELD,
                weight=1.3
            )
            self._entity_counts["fields"][field] = \
                self._entity_counts["fields"].get(field, 0) + 1
        
        # æ·»åŠ åº”ç”¨åœºæ™¯èŠ‚ç‚¹å’Œè¾¹
        for app in normalized_entities.get("applications", []):
            self._add_entity_node(app, NODE_TYPE_APPLICATION)
            self.graph.add_edge(
                doc_name, app,
                edge_type=EDGE_HAS_APPLICATION,
                weight=1.1
            )
            self._entity_counts["applications"][app] = \
                self._entity_counts["applications"].get(app, 0) + 1
    
    def _add_entity_node(self, entity_name: str, entity_type: str) -> None:
        """
        æ·»åŠ å®ä½“èŠ‚ç‚¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        
        Args:
            entity_name: å®ä½“åç§°
            entity_type: å®ä½“ç±»å‹
        """
        if entity_name not in self.graph:
            # æ ¹æ®ç±»å‹è®¾ç½®ä¸åŒçš„æ ‡ç­¾å›¾æ ‡
            icon_map = {
                NODE_TYPE_KEYWORD: "ğŸ·ï¸",
                NODE_TYPE_METHOD: "âš™ï¸",
                NODE_TYPE_DATASET: "ğŸ“Š",
                NODE_TYPE_FIELD: "ğŸ“–",
                NODE_TYPE_APPLICATION: "ğŸ’»"
            }
            icon = icon_map.get(entity_type, "")
            
            self.graph.add_node(
                entity_name,
                node_type=entity_type,
                label=entity_name,
                title=f"{icon} {entity_name}"
            )
    
    def build_from_extraction_results(
        self,
        extraction_results: Dict[str, Dict[str, List[str]]]
    ) -> None:
        """
        ä»å®ä½“æå–ç»“æœæ‰¹é‡æ„å»ºå›¾è°±
        
        Args:
            extraction_results: EntityExtractor.extract_from_documents çš„è¾“å‡º
        """
        for doc_name, entities in extraction_results.items():
            self.add_document(doc_name, entities)
    
    def get_document_nodes(self) -> List[str]:
        """è·å–æ‰€æœ‰æ–‡æ¡£èŠ‚ç‚¹"""
        return [
            node for node, data in self.graph.nodes(data=True)
            if data.get("node_type") == NODE_TYPE_DOCUMENT
        ]
    
    def get_entity_nodes(self, entity_type: Optional[str] = None) -> List[str]:
        """
        è·å–å®ä½“èŠ‚ç‚¹
        
        Args:
            entity_type: å¯é€‰ï¼ŒæŒ‡å®šå®ä½“ç±»å‹è¿‡æ»¤
            
        Returns:
            å®ä½“èŠ‚ç‚¹åˆ—è¡¨
        """
        if entity_type:
            return [
                node for node, data in self.graph.nodes(data=True)
                if data.get("node_type") == entity_type
            ]
        else:
            return [
                node for node, data in self.graph.nodes(data=True)
                if data.get("node_type") != NODE_TYPE_DOCUMENT
            ]
    
    def get_shared_entities(self, doc1: str, doc2: str) -> List[str]:
        """
        è·å–ä¸¤ç¯‡æ–‡æ¡£çš„å…±åŒå®ä½“
        
        Args:
            doc1: ç¬¬ä¸€ç¯‡æ–‡æ¡£å
            doc2: ç¬¬äºŒç¯‡æ–‡æ¡£å
            
        Returns:
            å…±åŒå®ä½“åˆ—è¡¨
        """
        neighbors1 = set(self.graph.neighbors(doc1)) if doc1 in self.graph else set()
        neighbors2 = set(self.graph.neighbors(doc2)) if doc2 in self.graph else set()
        return list(neighbors1 & neighbors2)
    
    def get_related_documents(self, doc_name: str) -> List[Tuple[str, List[str]]]:
        """
        è·å–ä¸æŒ‡å®šæ–‡æ¡£ç›¸å…³çš„å…¶ä»–æ–‡æ¡£åŠå…±äº«å®ä½“
        
        Args:
            doc_name: æ–‡æ¡£å
            
        Returns:
            [(ç›¸å…³æ–‡æ¡£å, [å…±äº«å®ä½“])] åˆ—è¡¨ï¼ŒæŒ‰å…±äº«å®ä½“æ•°é‡æ’åº
        """
        if doc_name not in self.graph:
            return []
        
        # è·å–è¯¥æ–‡æ¡£çš„æ‰€æœ‰å®ä½“é‚»å±…
        entities = set(self.graph.neighbors(doc_name))
        
        # æŸ¥æ‰¾å…±äº«è¿™äº›å®ä½“çš„å…¶ä»–æ–‡æ¡£
        related = {}
        for entity in entities:
            for neighbor in self.graph.neighbors(entity):
                if neighbor != doc_name and \
                   self.graph.nodes[neighbor].get("node_type") == NODE_TYPE_DOCUMENT:
                    if neighbor not in related:
                        related[neighbor] = []
                    related[neighbor].append(entity)
        
        # æŒ‰å…±äº«å®ä½“æ•°é‡æ’åº
        sorted_related = sorted(
            related.items(),
            key=lambda x: len(x[1]),
            reverse=True
        )
        
        return sorted_related
    
    def get_entity_sources(self, entity_name: str) -> List[str]:
        """
        è·å–æŸä¸ªå®ä½“æ¥è‡ªå“ªäº›æ–‡çŒ®
        
        Args:
            entity_name: å®ä½“åç§°
            
        Returns:
            åŒ…å«è¯¥å®ä½“çš„æ–‡æ¡£åç§°åˆ—è¡¨
        """
        sources = []
        for doc_name, entities in self._document_entities.items():
            # æ£€æŸ¥æ‰€æœ‰å®ä½“ç±»å‹
            all_entities = []
            for entity_list in entities.values():
                all_entities.extend(entity_list)
            if entity_name in all_entities:
                sources.append(doc_name)
        return sources
    
    def _rebuild_canonical_forms(self) -> None:
        """
        ä» document_entities é‡æ–°æ„å»ºå®ä½“è§„èŒƒåŒ–æ˜ å°„
        ç”¨äºåŠ è½½æ²¡æœ‰ä¿å­˜ canonical_forms çš„æ—§ç‰ˆå›¾è°±
        """
        self._entity_canonical_forms = {}
        
        # æ”¶é›†æ‰€æœ‰å®ä½“
        all_entities = []
        for doc_entities in self._document_entities.values():
            for entity_list in doc_entities.values():
                all_entities.extend(entity_list)
        
        # æŒ‰ç…§å½’ä¸€åŒ–è§„åˆ™å¤„ç†æ¯ä¸ªå®ä½“
        for entity in all_entities:
            base_name = self._extract_base_name(entity)
            
            if base_name in self._entity_canonical_forms:
                existing = self._entity_canonical_forms[base_name]
                # è¯„åˆ†å‡½æ•°ï¼šä¼˜å…ˆä¿ç•™æ›´å®Œæ•´çš„ç‰ˆæœ¬
                def score(name):
                    s = 0
                    if any('\u4e00' <= c <= '\u9fff' for c in name):
                        s += 100  # åŒ…å«ä¸­æ–‡
                    if '(' in name or 'ï¼ˆ' in name:
                        s += 50   # åŒ…å«æ‹¬å·æ³¨é‡Š
                    s += min(len(name), 80)  # é•¿åº¦
                    return s
                
                if score(entity) > score(existing):
                    self._entity_canonical_forms[base_name] = entity
            else:
                self._entity_canonical_forms[base_name] = entity
        
        print(f"ğŸ”„ å·²é‡å»ºå®ä½“è§„èŒƒåŒ–æ˜ å°„: {len(self._entity_canonical_forms)} ä¸ªåŸºç¡€å®ä½“")
    
    def get_all_entities_by_type(self, entity_type: str) -> List[Tuple[str, int]]:
        """
        è·å–æŒ‡å®šç±»å‹çš„æ‰€æœ‰å®ä½“åŠå…¶å‡ºç°æ¬¡æ•°
        
        Args:
            entity_type: å®ä½“ç±»å‹ (keywords, methods, datasets, fields, applications)
            
        Returns:
            [(å®ä½“åç§°, å‡ºç°æ¬¡æ•°)] åˆ—è¡¨ï¼ŒæŒ‰æ¬¡æ•°é™åºæ’åˆ—
        """
        counts = self._entity_counts.get(entity_type, {})
        return sorted(counts.items(), key=lambda x: x[1], reverse=True)
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–å›¾è°±ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        doc_nodes = self.get_document_nodes()
        keyword_nodes = self.get_entity_nodes(NODE_TYPE_KEYWORD)
        method_nodes = self.get_entity_nodes(NODE_TYPE_METHOD)
        dataset_nodes = self.get_entity_nodes(NODE_TYPE_DATASET)
        field_nodes = self.get_entity_nodes(NODE_TYPE_FIELD)
        application_nodes = self.get_entity_nodes(NODE_TYPE_APPLICATION)
        
        # è·å–æœ€å¸¸è§çš„å®ä½“
        top_keywords = sorted(
            self._entity_counts["keywords"].items(),
            key=lambda x: x[1], reverse=True
        )[:5]
        top_methods = sorted(
            self._entity_counts["methods"].items(),
            key=lambda x: x[1], reverse=True
        )[:5]
        top_fields = sorted(
            self._entity_counts["fields"].items(),
            key=lambda x: x[1], reverse=True
        )[:3]
        top_datasets = sorted(
            self._entity_counts["datasets"].items(),
            key=lambda x: x[1], reverse=True
        )[:5]
        
        # è·å–æ‰€æœ‰å®ä½“å®Œæ•´åˆ—è¡¨
        all_keywords = self.get_all_entities_by_type("keywords")
        all_methods = self.get_all_entities_by_type("methods")
        all_datasets = self.get_all_entities_by_type("datasets")
        all_fields = self.get_all_entities_by_type("fields")
        all_applications = self.get_all_entities_by_type("applications")
        
        return {
            "total_nodes": self.graph.number_of_nodes(),
            "total_edges": self.graph.number_of_edges(),
            "document_count": len(doc_nodes),
            "keyword_count": len(keyword_nodes),
            "method_count": len(method_nodes),
            "dataset_count": len(dataset_nodes),
            "field_count": len(field_nodes),
            "application_count": len(application_nodes),
            "top_keywords": top_keywords,
            "top_methods": top_methods,
            "top_fields": top_fields,
            "top_datasets": top_datasets,
            "documents": doc_nodes,
            # å®Œæ•´å®ä½“åˆ—è¡¨
            "all_keywords": all_keywords,
            "all_methods": all_methods,
            "all_datasets": all_datasets,
            "all_fields": all_fields,
            "all_applications": all_applications,
            # æ–‡æ¡£-å®ä½“æ˜ å°„ (ç”¨äºæŸ¥è¯¢å®ä½“æ¥æº)
            "document_entities": self._document_entities
        }
    
    def save(self, filepath: Optional[str] = None) -> str:
        """
        å°†å›¾è°±ä¿å­˜ä¸º JSON æ–‡ä»¶
        
        Args:
            filepath: ä¿å­˜è·¯å¾„ï¼Œé»˜è®¤ä¿å­˜åˆ° data/graphs/
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if filepath is None:
            filepath = str(GRAPHS_DIR / "knowledge_graph.json")
        
        # æ„å»ºå¯åºåˆ—åŒ–çš„æ•°æ®ç»“æ„
        data = {
            "nodes": [
                {
                    "id": node,
                    **attrs
                }
                for node, attrs in self.graph.nodes(data=True)
            ],
            "edges": [
                {
                    "source": u,
                    "target": v,
                    **attrs
                }
                for u, v, attrs in self.graph.edges(data=True)
            ],
            "document_entities": self._document_entities,
            "entity_counts": self._entity_counts,
            "entity_canonical_forms": self._entity_canonical_forms  # ä¿å­˜å®ä½“è§„èŒƒåŒ–æ˜ å°„
        }
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… å›¾è°±å·²ä¿å­˜åˆ°: {filepath}")
        return filepath
    
    def load(self, filepath: Optional[str] = None) -> bool:
        """
        ä» JSON æ–‡ä»¶åŠ è½½å›¾è°±
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        if filepath is None:
            filepath = str(GRAPHS_DIR / "knowledge_graph.json")
        
        if not os.path.exists(filepath):
            print(f"âš ï¸ å›¾è°±æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
            return False
        
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            # é‡å»ºå›¾
            self.graph = nx.Graph()
            
            # æ·»åŠ èŠ‚ç‚¹
            for node_data in data.get("nodes", []):
                node_id = node_data.pop("id")
                self.graph.add_node(node_id, **node_data)
            
            # æ·»åŠ è¾¹
            for edge_data in data.get("edges", []):
                source = edge_data.pop("source")
                target = edge_data.pop("target")
                self.graph.add_edge(source, target, **edge_data)
            
            # æ¢å¤å…ƒæ•°æ®
            self._document_entities = data.get("document_entities", {})
            self._entity_counts = data.get("entity_counts", {
                "keywords": {}, "methods": {}, "datasets": {},
                "fields": {}, "applications": {}
            })
            
            # æ¢å¤å®ä½“è§„èŒƒåŒ–æ˜ å°„
            self._entity_canonical_forms = data.get("entity_canonical_forms", {})
            
            # å¦‚æœæ²¡æœ‰ä¿å­˜çš„ canonical_formsï¼Œåˆ™ä» document_entities é‡æ–°æ„å»º
            if not self._entity_canonical_forms:
                self._rebuild_canonical_forms()
            
            print(f"âœ… å›¾è°±å·²åŠ è½½: {self.graph.number_of_nodes()} èŠ‚ç‚¹, {self.graph.number_of_edges()} è¾¹")
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½å›¾è°±å¤±è´¥: {e}")
            return False
    
    def clear(self) -> None:
        """æ¸…ç©ºå›¾è°±"""
        self.graph.clear()
        self._document_entities.clear()
        self._entity_canonical_forms.clear()
        self._entity_counts = {
            "keywords": {}, "methods": {}, "datasets": {},
            "fields": {}, "applications": {}
        }
        print("ğŸ—‘ï¸ å›¾è°±å·²æ¸…ç©º")


def create_knowledge_graph() -> KnowledgeGraph:
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºçŸ¥è¯†å›¾è°±å®ä¾‹
    
    Returns:
        KnowledgeGraph å®ä¾‹
    """
    return KnowledgeGraph()
