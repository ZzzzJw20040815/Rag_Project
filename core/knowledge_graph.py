"""
çŸ¥è¯†å›¾è°±æ„å»ºæ¨¡å—
ä½¿ç”¨ NetworkX æ„å»ºæ–‡æ¡£-å®ä½“å…±ç°ç½‘ç»œ

ä¸»è¦åŠŸèƒ½ï¼š
- æ„å»ºæ–‡æ¡£ä¸å®ä½“çš„å…³è”å›¾
- æ”¯æŒå¤šç§å®ä½“ç±»å‹ï¼ˆå…³é”®è¯ã€æ–¹æ³•ã€æ•°æ®é›†ï¼‰
- å›¾è°±æŒä¹…åŒ–ä¸åŠ è½½
"""

import json
import os
from typing import Dict, List, Optional, Set, Tuple, Any
from pathlib import Path
import networkx as nx

import sys
sys.path.append(str(Path(__file__).parent.parent))
from config import GRAPHS_DIR


# èŠ‚ç‚¹ç±»å‹å¸¸é‡
NODE_TYPE_DOCUMENT = "document"
NODE_TYPE_KEYWORD = "keyword"
NODE_TYPE_METHOD = "method"
NODE_TYPE_DATASET = "dataset"
NODE_TYPE_FIELD = "field"  # ç ”ç©¶é¢†åŸŸ
NODE_TYPE_APPLICATION = "application"  # åº”ç”¨åœºæ™¯

# è¾¹ç±»å‹å¸¸é‡
EDGE_CONTAINS_KEYWORD = "CONTAINS_KEYWORD"
EDGE_USES_METHOD = "USES_METHOD"
EDGE_USES_DATASET = "USES_DATASET"
EDGE_BELONGS_TO_FIELD = "BELONGS_TO_FIELD"
EDGE_HAS_APPLICATION = "HAS_APPLICATION"


class KnowledgeGraph:
    """
    çŸ¥è¯†å›¾è°±ç±»
    å°è£… NetworkX å›¾æ“ä½œï¼Œæ„å»ºæ–‡æ¡£-å®ä½“å…±ç°ç½‘ç»œ
    """
    
    def __init__(self):
        """åˆå§‹åŒ–çŸ¥è¯†å›¾è°±"""
        # ä½¿ç”¨æ— å‘å›¾
        self.graph = nx.Graph()
        
        # å­˜å‚¨æ–‡æ¡£åŠå…¶å®ä½“çš„æ˜ å°„
        self._document_entities: Dict[str, Dict[str, List[str]]] = {}
        
        # å®ä½“ç»Ÿè®¡ - æ”¯æŒæ›´å¤šå®ä½“ç±»å‹
        self._entity_counts: Dict[str, Dict[str, int]] = {
            "keywords": {},
            "methods": {},
            "datasets": {},
            "fields": {},
            "applications": {}
        }
    
    def add_document(
        self,
        doc_name: str,
        entities: Dict[str, List[str]]
    ) -> None:
        """
        æ·»åŠ æ–‡æ¡£åŠå…¶å®ä½“åˆ°å›¾è°±
        
        Args:
            doc_name: æ–‡æ¡£åç§°
            entities: å®ä½“å­—å…¸ï¼ŒåŒ…å« keywords, methods, datasets
        """
        # æ¸…ç†æ–‡æ¡£åï¼ˆç§»é™¤è·¯å¾„ï¼Œåªä¿ç•™æ–‡ä»¶åï¼‰
        doc_name = Path(doc_name).stem if "/" in doc_name or "\\" in doc_name else doc_name
        
        # å­˜å‚¨æ–‡æ¡£å®ä½“æ˜ å°„
        self._document_entities[doc_name] = entities
        
        # æ·»åŠ æ–‡æ¡£èŠ‚ç‚¹
        self.graph.add_node(
            doc_name,
            node_type=NODE_TYPE_DOCUMENT,
            label=doc_name,
            title=f"ğŸ“„ {doc_name}"
        )
        
        # æ·»åŠ å…³é”®è¯èŠ‚ç‚¹å’Œè¾¹
        for keyword in entities.get("keywords", []):
            self._add_entity_node(keyword, NODE_TYPE_KEYWORD)
            self.graph.add_edge(
                doc_name, keyword,
                edge_type=EDGE_CONTAINS_KEYWORD,
                weight=1.0
            )
            self._entity_counts["keywords"][keyword] = \
                self._entity_counts["keywords"].get(keyword, 0) + 1
        
        # æ·»åŠ æ–¹æ³•èŠ‚ç‚¹å’Œè¾¹
        for method in entities.get("methods", []):
            self._add_entity_node(method, NODE_TYPE_METHOD)
            self.graph.add_edge(
                doc_name, method,
                edge_type=EDGE_USES_METHOD,
                weight=1.5  # æ–¹æ³•å…³è”æƒé‡æ›´é«˜
            )
            self._entity_counts["methods"][method] = \
                self._entity_counts["methods"].get(method, 0) + 1
        
        # æ·»åŠ æ•°æ®é›†èŠ‚ç‚¹å’Œè¾¹
        for dataset in entities.get("datasets", []):
            self._add_entity_node(dataset, NODE_TYPE_DATASET)
            self.graph.add_edge(
                doc_name, dataset,
                edge_type=EDGE_USES_DATASET,
                weight=1.2
            )
            self._entity_counts["datasets"][dataset] = \
                self._entity_counts["datasets"].get(dataset, 0) + 1
        
        # æ·»åŠ ç ”ç©¶é¢†åŸŸèŠ‚ç‚¹å’Œè¾¹
        for field in entities.get("fields", []):
            self._add_entity_node(field, NODE_TYPE_FIELD)
            self.graph.add_edge(
                doc_name, field,
                edge_type=EDGE_BELONGS_TO_FIELD,
                weight=1.3
            )
            self._entity_counts["fields"][field] = \
                self._entity_counts["fields"].get(field, 0) + 1
        
        # æ·»åŠ åº”ç”¨åœºæ™¯èŠ‚ç‚¹å’Œè¾¹
        for app in entities.get("applications", []):
            self._add_entity_node(app, NODE_TYPE_APPLICATION)
            self.graph.add_edge(
                doc_name, app,
                edge_type=EDGE_HAS_APPLICATION,
                weight=1.1
            )
            self._entity_counts["applications"][app] = \
                self._entity_counts["applications"].get(app, 0) + 1
    
    def _add_entity_node(self, entity_name: str, entity_type: str) -> None:
        """
        æ·»åŠ å®ä½“èŠ‚ç‚¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        
        Args:
            entity_name: å®ä½“åç§°
            entity_type: å®ä½“ç±»å‹
        """
        if entity_name not in self.graph:
            # æ ¹æ®ç±»å‹è®¾ç½®ä¸åŒçš„æ ‡ç­¾å›¾æ ‡
            icon_map = {
                NODE_TYPE_KEYWORD: "ğŸ·ï¸",
                NODE_TYPE_METHOD: "âš™ï¸",
                NODE_TYPE_DATASET: "ğŸ“Š",
                NODE_TYPE_FIELD: "ğŸ“–",
                NODE_TYPE_APPLICATION: "ğŸ’»"
            }
            icon = icon_map.get(entity_type, "")
            
            self.graph.add_node(
                entity_name,
                node_type=entity_type,
                label=entity_name,
                title=f"{icon} {entity_name}"
            )
    
    def build_from_extraction_results(
        self,
        extraction_results: Dict[str, Dict[str, List[str]]]
    ) -> None:
        """
        ä»å®ä½“æå–ç»“æœæ‰¹é‡æ„å»ºå›¾è°±
        
        Args:
            extraction_results: EntityExtractor.extract_from_documents çš„è¾“å‡º
        """
        for doc_name, entities in extraction_results.items():
            self.add_document(doc_name, entities)
    
    def get_document_nodes(self) -> List[str]:
        """è·å–æ‰€æœ‰æ–‡æ¡£èŠ‚ç‚¹"""
        return [
            node for node, data in self.graph.nodes(data=True)
            if data.get("node_type") == NODE_TYPE_DOCUMENT
        ]
    
    def get_entity_nodes(self, entity_type: Optional[str] = None) -> List[str]:
        """
        è·å–å®ä½“èŠ‚ç‚¹
        
        Args:
            entity_type: å¯é€‰ï¼ŒæŒ‡å®šå®ä½“ç±»å‹è¿‡æ»¤
            
        Returns:
            å®ä½“èŠ‚ç‚¹åˆ—è¡¨
        """
        if entity_type:
            return [
                node for node, data in self.graph.nodes(data=True)
                if data.get("node_type") == entity_type
            ]
        else:
            return [
                node for node, data in self.graph.nodes(data=True)
                if data.get("node_type") != NODE_TYPE_DOCUMENT
            ]
    
    def get_shared_entities(self, doc1: str, doc2: str) -> List[str]:
        """
        è·å–ä¸¤ç¯‡æ–‡æ¡£çš„å…±åŒå®ä½“
        
        Args:
            doc1: ç¬¬ä¸€ç¯‡æ–‡æ¡£å
            doc2: ç¬¬äºŒç¯‡æ–‡æ¡£å
            
        Returns:
            å…±åŒå®ä½“åˆ—è¡¨
        """
        neighbors1 = set(self.graph.neighbors(doc1)) if doc1 in self.graph else set()
        neighbors2 = set(self.graph.neighbors(doc2)) if doc2 in self.graph else set()
        return list(neighbors1 & neighbors2)
    
    def get_related_documents(self, doc_name: str) -> List[Tuple[str, List[str]]]:
        """
        è·å–ä¸æŒ‡å®šæ–‡æ¡£ç›¸å…³çš„å…¶ä»–æ–‡æ¡£åŠå…±äº«å®ä½“
        
        Args:
            doc_name: æ–‡æ¡£å
            
        Returns:
            [(ç›¸å…³æ–‡æ¡£å, [å…±äº«å®ä½“])] åˆ—è¡¨ï¼ŒæŒ‰å…±äº«å®ä½“æ•°é‡æ’åº
        """
        if doc_name not in self.graph:
            return []
        
        # è·å–è¯¥æ–‡æ¡£çš„æ‰€æœ‰å®ä½“é‚»å±…
        entities = set(self.graph.neighbors(doc_name))
        
        # æŸ¥æ‰¾å…±äº«è¿™äº›å®ä½“çš„å…¶ä»–æ–‡æ¡£
        related = {}
        for entity in entities:
            for neighbor in self.graph.neighbors(entity):
                if neighbor != doc_name and \
                   self.graph.nodes[neighbor].get("node_type") == NODE_TYPE_DOCUMENT:
                    if neighbor not in related:
                        related[neighbor] = []
                    related[neighbor].append(entity)
        
        # æŒ‰å…±äº«å®ä½“æ•°é‡æ’åº
        sorted_related = sorted(
            related.items(),
            key=lambda x: len(x[1]),
            reverse=True
        )
        
        return sorted_related
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–å›¾è°±ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        doc_nodes = self.get_document_nodes()
        keyword_nodes = self.get_entity_nodes(NODE_TYPE_KEYWORD)
        method_nodes = self.get_entity_nodes(NODE_TYPE_METHOD)
        dataset_nodes = self.get_entity_nodes(NODE_TYPE_DATASET)
        field_nodes = self.get_entity_nodes(NODE_TYPE_FIELD)
        application_nodes = self.get_entity_nodes(NODE_TYPE_APPLICATION)
        
        # è·å–æœ€å¸¸è§çš„å®ä½“
        top_keywords = sorted(
            self._entity_counts["keywords"].items(),
            key=lambda x: x[1], reverse=True
        )[:5]
        top_methods = sorted(
            self._entity_counts["methods"].items(),
            key=lambda x: x[1], reverse=True
        )[:5]
        top_fields = sorted(
            self._entity_counts["fields"].items(),
            key=lambda x: x[1], reverse=True
        )[:3]
        
        return {
            "total_nodes": self.graph.number_of_nodes(),
            "total_edges": self.graph.number_of_edges(),
            "document_count": len(doc_nodes),
            "keyword_count": len(keyword_nodes),
            "method_count": len(method_nodes),
            "dataset_count": len(dataset_nodes),
            "field_count": len(field_nodes),
            "application_count": len(application_nodes),
            "top_keywords": top_keywords,
            "top_methods": top_methods,
            "top_fields": top_fields,
            "documents": doc_nodes
        }
    
    def save(self, filepath: Optional[str] = None) -> str:
        """
        å°†å›¾è°±ä¿å­˜ä¸º JSON æ–‡ä»¶
        
        Args:
            filepath: ä¿å­˜è·¯å¾„ï¼Œé»˜è®¤ä¿å­˜åˆ° data/graphs/
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if filepath is None:
            filepath = str(GRAPHS_DIR / "knowledge_graph.json")
        
        # æ„å»ºå¯åºåˆ—åŒ–çš„æ•°æ®ç»“æ„
        data = {
            "nodes": [
                {
                    "id": node,
                    **attrs
                }
                for node, attrs in self.graph.nodes(data=True)
            ],
            "edges": [
                {
                    "source": u,
                    "target": v,
                    **attrs
                }
                for u, v, attrs in self.graph.edges(data=True)
            ],
            "document_entities": self._document_entities,
            "entity_counts": self._entity_counts
        }
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… å›¾è°±å·²ä¿å­˜åˆ°: {filepath}")
        return filepath
    
    def load(self, filepath: Optional[str] = None) -> bool:
        """
        ä» JSON æ–‡ä»¶åŠ è½½å›¾è°±
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        if filepath is None:
            filepath = str(GRAPHS_DIR / "knowledge_graph.json")
        
        if not os.path.exists(filepath):
            print(f"âš ï¸ å›¾è°±æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
            return False
        
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            # é‡å»ºå›¾
            self.graph = nx.Graph()
            
            # æ·»åŠ èŠ‚ç‚¹
            for node_data in data.get("nodes", []):
                node_id = node_data.pop("id")
                self.graph.add_node(node_id, **node_data)
            
            # æ·»åŠ è¾¹
            for edge_data in data.get("edges", []):
                source = edge_data.pop("source")
                target = edge_data.pop("target")
                self.graph.add_edge(source, target, **edge_data)
            
            # æ¢å¤å…ƒæ•°æ®
            self._document_entities = data.get("document_entities", {})
            self._entity_counts = data.get("entity_counts", {
                "keywords": {}, "methods": {}, "datasets": {}
            })
            
            print(f"âœ… å›¾è°±å·²åŠ è½½: {self.graph.number_of_nodes()} èŠ‚ç‚¹, {self.graph.number_of_edges()} è¾¹")
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½å›¾è°±å¤±è´¥: {e}")
            return False
    
    def clear(self) -> None:
        """æ¸…ç©ºå›¾è°±"""
        self.graph.clear()
        self._document_entities.clear()
        self._entity_counts = {
            "keywords": {}, "methods": {}, "datasets": {},
            "fields": {}, "applications": {}
        }
        print("ğŸ—‘ï¸ å›¾è°±å·²æ¸…ç©º")


def create_knowledge_graph() -> KnowledgeGraph:
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºçŸ¥è¯†å›¾è°±å®ä¾‹
    
    Returns:
        KnowledgeGraph å®ä¾‹
    """
    return KnowledgeGraph()
